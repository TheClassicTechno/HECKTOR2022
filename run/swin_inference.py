# -*- coding: utf-8 -*-
"""SwinUNet Inference

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ePtLD3-Ve2yXBVe3vlA5haTxxkTbfrEB
"""

import numpy as np
import os

import tensorflow as tf
from tensorflow import keras

import torch
from torch import nn
import torch.nn.functional as tnf
from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler
import torch.optim as optim

import sklearn
from sklearn.model_selection import KFold



from volumentations import *
import nibabel as nib
from monai.losses import DiceLoss
from monai.inferers import sliding_window_inference
from monai import transforms
from monai.transforms import (
    AsDiscrete,
    Activations,
)

from monai.config import print_config
from monai.metrics import DiceMetric
from monai.utils.enums import MetricReduction
from monai.networks.nets import SwinUNETR, UNETR
from monai import data
from monai.data import decollate_batch
from functools import partial

root_dir = "datasets/imagesTs"
batch_size = 1
num_workers = 2
total_epoch = 200
lr = 0.0001
device = torch.device("cuda:0")

model = SwinUNETR(
    img_size=(160, 160, 64),
    in_channels=2,
    out_channels=3,
    feature_size=48,
    drop_rate=0.0,
    attn_drop_rate=0.0,
    dropout_path_rate=0.0
).to(device)
model.load_state_dict(torch.load('SWIN_UNETR_final.pth'))

def load_data(root_dir, filename, split, aug):
  filename = filename.upper()
  dir_img = os.path.join(root_dir, "imagesTr")
  dir_seg = os.path.join(root_dir, "labelsTr")
  if split == 'test':
    dir_img = os.path.join(root_dir, "imagesTs")
    dir_seg = os.path.join(root_dir, "labelsTs")
  filename_ct = os.path.join(dir_img,  filename[:-7] + '_0000.nii.gz')
  filename_pt = os.path.join(dir_img, filename[:-7] + '_0001.nii.gz')
  filename_mask = os.path.join(dir_seg, filename[:-7] + '.nii.gz')
  ct_img = np.expand_dims(nib.load(filename_ct).get_fdata(), axis = 3)
  pet_img = np.expand_dims(nib.load(filename_pt).get_fdata(), axis = 3)
  mask = nib.load(filename_mask).get_fdata()
  # mask_1 = np.expand_dims((mask==1.).astype(np.float32), axis = 3)
  # mask_2 = np.expand_dims((mask==2.).astype(np.float32), axis = 3)
  # mask = np.concatenate([mask_0, mask_1, mask_2], axis=3)
  mask = keras.utils.to_categorical(
   mask, num_classes=3, dtype='float32'
  )
  img = np.concatenate((ct_img, pet_img), axis = 3)
  if aug: 
    if(split == 'train'):
      aug = get_augmentation_train((160, 160, 64))
    else:
      aug = get_augmentation_test((160, 160, 64))
    data = {'image': img, 'mask': mask}
    aug_data = aug(**data)
    img, mask = aug_data['image'], aug_data['mask']
    img, mask = img.transpose(3 , 0, 1, 2).astype(np.float32), mask.transpose(3, 0, 1, 2).astype(np.float32)
    return img, mask
  else:
    img, mask = img.transpose(3 , 0, 1, 2), mask.transpose(3, 0, 1, 2)
    return img, mask

class HEKDataset(Dataset):
    def __init__(self, root_dir, split='train'):
        self.root_dir = root_dir
        self.split = split
        self.image_paths = []
        # Load data index
        if split == 'train':
          for path in os.listdir(os.path.join(root_dir, "labelsTr")):
                  self.image_paths.append(path)
        else:
          for path in os.listdir(os.path.join(root_dir, "labelsTs")):
              self.image_paths.append(path)
        print('Succesfully loaded {} dataset.'.format(split) + ' '*50)
            
            
    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        filename = self.image_paths[idx]
        return load_data(self.root_dir, filename, self.split, True)
model.eval()

save_dir = "/datasets/swin_output/
b = 1
with torch.no_grad():
  for path in os.listdir(os.path.join(root_dir)):
    if path.endswith("1.nii.gz"):
      continue
    filename_ct = os.path.join(root_dir, path[:-8] + '0.nii.gz')
    filename_pt = os.path.join(root_dir, path[:-8] + '1.nii.gz')

    ct_img = np.expand_dims(nib.load(filename_ct).get_fdata(), axis = 3)
    pet_img = np.expand_dims(nib.load(filename_pt).get_fdata(), axis = 3)
    img = np.concatenate((ct_img, pet_img), axis = 3)
    img = np.expand_dims(img.transpose(3 , 0, 1, 2), axis = 0)
    img = torch.from_numpy(img).to(device).float()
    print(path[:-12], img.size())
    logits = model(img)
    preds = torch.argmax(logits, axis = 1).cpu().numpy()[0]
    out = preds.transpose(2, 1, 0)
    np.save(os.path.join(save_dir, path[:-12] + ".npy"), out)
    b += 1